{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f6f5859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import json\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90ebc8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../creds.yaml\", \"r\") as f:\n",
    "            creds = yaml.safe_load(f)\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = creds[\"LANGCHAIN\"][\"LANGCHAIN_API_KEY\"]\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = creds[\"OPENAI\"][\"OPENAI_API_KEY\"]\n",
    "os.environ[\"OPENAI_BASE_URL\"] = \"https://pro.aiskt.com/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41caafed",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"VAST Captions\"\n",
    "\n",
    "video_dir = \"../inputs/val_set\"\n",
    "file_path = \"../inputs/annotations/val_annotations.json\"\n",
    "with open(file_path, \"r\") as f:\n",
    "    ann = json.load(f)\n",
    "\n",
    "cap_list = [value[\"cap\"][0] for elem in ann[\"annotations\"].values() for value in elem.values()]\n",
    "cap_list = list(set(cap_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c82b6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Introduction:\n",
    "The user is creating ground truth captions for some MEDICAL video segments.\n",
    "The original captions are formulated as some consumers' first aid, medical emergency, and medical educational questions.\n",
    "Your task is to formulate these captions as declarative sentences and generate THREE different versions from different perspectives.\n",
    "\n",
    "Objective\n",
    "The final objective is to improve the generalization capabilities of a video captioning model by increasing the DIVERSITY of the ground truth captions.\n",
    "\n",
    "Instructions:\n",
    "1. Understand the Medical Question: Ensure that the core concerns of the patient, including symptoms and body parts, are preserved in all generated versions.\n",
    "2. Reformulate the Sentence to be Declarative: Convert the original caption from a question format to a declarative sentence format. Ensure the declarative sentence describes a medical situation suitable for the context being questioned.\n",
    "3. Diversify Perspectives: Vary the medical situation by considering different angles such as possible medical history, user's living habits, potential treatments or interventions.\n",
    "\n",
    "Please separate new capations separated by newlines.\n",
    "\n",
    "Examples:\n",
    "Input: \n",
    "How to stretch the quadricep muscles to prevent arthritis?\n",
    "Output:\n",
    "Regularly stretching the quadricep muscles helps maintain joint flexibility and may reduce the risk of developing arthritis.\n",
    "Performing quadricep stretches can improve muscle strength and support knee joint health, potentially preventing arthritis.\n",
    "Engaging in daily quadricep stretches enhances muscle elasticity and may lower the likelihood of arthritis.\n",
    "\n",
    "The original caption: {caption}\n",
    "\"\"\"\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "generate_queries = (\n",
    "    prompt_perspectives \n",
    "    | ChatOpenAI(temperature=0.2) \n",
    "    | StrOutputParser() \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "087c7f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_output = {}\n",
    "for cap in cap_list:\n",
    "    docs = generate_queries.invoke({\"caption\": cap})\n",
    "    gen_output[cap] = docs\n",
    "\n",
    "with open(\"vast_ann_backup.json\", \"w\") as f:\n",
    "    json.dump(gen_output, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4178f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_duration(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return None\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = frame_count / fps\n",
    "    cap.release()\n",
    "    return frame_count, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9774f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../captions_ann/vast_ann_backup_val.json\", \"r\") as f:\n",
    "    gen_output = json.load(f)\n",
    "\n",
    "vast_ann = []\n",
    "for vid_name, labels in ann[\"annotations\"].items():\n",
    "    frame_count, duration = get_video_duration(os.path.join(video_dir, vid_name) + \".mp4\")\n",
    "    for i, elem in enumerate(labels.values()):\n",
    "        raw_cap = gen_output[elem[\"cap\"][0]]\n",
    "        raw_cap = raw_cap.split(\"\\n\")\n",
    "        \n",
    "        ann_i = {\n",
    "            \"video_id\": os.path.join(video_dir, vid_name) + \".mp4\" + f\"@{i}\",\n",
    "            \"caption\": raw_cap,\n",
    "            \"timestamp\": (np.array(elem[\"z\"]) / duration * frame_count).astype(int).tolist(),\n",
    "            \"event_id\": i,\n",
    "            \"duration\": duration,\n",
    "            \"frame_count\": frame_count,\n",
    "        }\n",
    "        vast_ann.append(ann_i)\n",
    "\n",
    "# validation\n",
    "with open(\"vast_ann_val.json\", \"w\") as f:\n",
    "    json.dump(vast_ann, f, indent=4)\n",
    "# validation\n",
    "with open(\"vast_annfile.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"type\": \"caption\",\n",
    "            \"annotations\": vast_ann\n",
    "        },\n",
    "        f,\n",
    "        indent=4\n",
    "    )\n",
    "# training\n",
    "with open(\"vast_ann_train.json\", \"w\") as f:\n",
    "    json.dump(vast_ann, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
