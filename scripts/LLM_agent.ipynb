{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a89d53cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain.load import dumps, loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4807a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../creds.yaml\", \"r\") as f:\n",
    "    creds = yaml.safe_load(f)\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = creds[\"LANGCHAIN\"][\"LANGCHAIN_API_KEY\"]\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = creds[\"OPENAI\"][\"OPENAI_API_KEY\"]\n",
    "os.environ[\"OPENAI_BASE_URL\"] = \"https://pro.aiskt.com/v1\"\n",
    "\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"LLM Agent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e61b1f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_duration(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return None\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = frame_count / fps\n",
    "    cap.release()\n",
    "    return frame_count, duration\n",
    "\n",
    "def time_converter(seconds):\n",
    "    minutes = seconds // 60\n",
    "    remaining_seconds = seconds % 60\n",
    "    return f\"{int(minutes)}:{int(remaining_seconds)}\"\n",
    "\n",
    "def build_corpus(vid, raw_pred):\n",
    "    frame_count, duration = get_video_duration(vid)\n",
    "\n",
    "    doc = []\n",
    "    for event in raw_pred:\n",
    "        for i, sent in enumerate(event[\"sentence\"]):\n",
    "            timestamp = event[\"timestamp\"]\n",
    "            real_time = list(map(time_converter, timestamp))\n",
    "            frame_range = list(map(lambda x: int(x / duration * frame_count), timestamp))\n",
    "            doc.append(Document(\n",
    "                page_content=sent,\n",
    "                metadata={\n",
    "                    \"vid\": vid,\n",
    "                    \"sent_id\": i,\n",
    "                    \"event_id\": event[\"event_id\"],\n",
    "                    \"timestamp_s\": timestamp[0],\n",
    "                    \"timestamp_e\": timestamp[1],\n",
    "                    \"real_time_s\": real_time[0],\n",
    "                    \"real_time_e\": real_time[1],\n",
    "                    \"frame_range_s\": frame_range[0],\n",
    "                    \"frame_range_e\": frame_range[1]\n",
    "                }\n",
    "            ))\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04c2cf60-d636-4992-a021-1236f7688999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data model\n",
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\" Unique union of retrieved docs \"\"\"\n",
    "    # Flatten list of lists, and convert each Document to string\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    # Get unique documents\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    unique_docs = [loads(doc) for doc in unique_docs]\n",
    "    unique_event = {\n",
    "        int(doc.metadata[\"event_id\"]): doc for doc in unique_docs\n",
    "    }\n",
    "    unique_event_list = list(zip(unique_event.keys(), unique_event.values()))\n",
    "    unique_event_list.sort(key=lambda x: x[0])\n",
    "    return [elem[-1] for elem in unique_event_list]\n",
    "\n",
    "def retrieval_chain(question, retriever):\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    context = \"\\n\".join(f\"Document {i + 1}: {doc.page_content}\" for i, doc in enumerate(retrieved_docs))\n",
    "\n",
    "    template = \"\"\"\n",
    "    Task: Medical Document Retrieval\n",
    "\n",
    "    Introduction:\n",
    "    In this task, you will be provided with a set of documents as reference that describe various medical scenarios.\n",
    "    Each document discusses a medical situation from different angles, including symptoms, affected body parts, potential treatments, etc.\n",
    "    Your objective is to determine which documents are relevant to a given user query.\n",
    "\n",
    "    Instructions:\n",
    "    1. Understand the Reference Documents:\n",
    "        - Each document is indexed with a positive number, following the format: \"Document X: ...\".\n",
    "        - Documents are separated by newlines.\n",
    "        - Ensure you fully comprehend the medical situation described in each document.\n",
    "    2. Understand the User's Question:\n",
    "        - Analyze the user's query to identify key concerns, such as symptoms, affected body parts, queried treatments, etc.\n",
    "    3. Compare and Identify Relevance:\n",
    "        - Compare the user's question with the content of the provided documents.\n",
    "        - Identify the documents that can POTENTIALLY address the concerns raised in the user's question as MANY as possible.\n",
    "    4. Output the Results:\n",
    "        - Provide the indices of the relevant documents.\n",
    "        - Separate the indices with commas (e.g., \"1, 2\").\n",
    "\n",
    "    Example:\n",
    "    Reference Documents:\n",
    "    Document 1: applying pressure on the head with a pillow can help alleviate pressure on the neck and provide relief from neck pain.\n",
    "    Document 2: performing neck pain and improve blood circulation through the head and shoulders, potentially reducing tension in the neck muscles and improve range of motion.\n",
    "    Document 3: regular self - massage techniques can be used to alleviate discomfort associated with pinched nerve in the neck.\n",
    "    Document 4: incorporating isometric neck movements into your routine can reduce discomfort associated with neck pain and improve flexibility.\n",
    "    Document 5: applying gentle pressure to the neck can help alleviate symptoms of cervical spasms.\n",
    "    Document 6: taking non-steroidal anti-inflammatory drugs and acetaminophen can help relieve sore throats.\n",
    "    Input Question:\n",
    "    \"I always suffer from neck pain. Can you give me some suggestions?\"\n",
    "    Answer:\n",
    "    1, 2, 3, 4, 5\n",
    "\n",
    "    Reference Documents: {context}\n",
    "    Input Question: {question}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    retrieval_chain = (\n",
    "        prompt\n",
    "        | ChatOpenAI(temperature=0)\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    output = retrieval_chain.invoke({\"context\": context, \"question\": question})\n",
    "    output = output.split(\"\\n\")[-1]\n",
    "    output = output.split(\": \")[-1]\n",
    "    output_idx = [int(elem) - 1 for elem in output.split(\", \")]\n",
    "    return output_idx, retrieved_docs\n",
    "\n",
    "def pipeline(question, retriever):\n",
    "    output_idx, retrieved_docs = retrieval_chain(question, retriever)\n",
    "    answer = [elem for i, elem in enumerate(retrieved_docs) if i in output_idx]\n",
    "    \n",
    "    output_vid = {}\n",
    "    for elem in answer:\n",
    "        if output_vid.get(elem.metadata[\"vid\"], None):\n",
    "            output_vid[elem.metadata[\"vid\"]][\"answers\"].update({\n",
    "                f\"{elem.metadata['real_time_s']}-{elem.metadata['real_time_e']}\": {\n",
    "                    \"real_time_s\": elem.metadata[\"real_time_s\"],\n",
    "                    \"real_time_e\": elem.metadata[\"real_time_e\"],\n",
    "                }\n",
    "            })\n",
    "        else:\n",
    "            output_vid[elem.metadata[\"vid\"]] = {\n",
    "                \"vid_source\": f\"https://www.youtube.com/watch?v={os.path.basename(elem.metadata['vid']).rsplit('.mp4')[0]}\",\n",
    "                \"answers\": {\n",
    "                    f\"{elem.metadata['real_time_s']}-{elem.metadata['real_time_e']}\": {\n",
    "                        \"real_time_s\": elem.metadata[\"real_time_s\"],\n",
    "                        \"real_time_e\": elem.metadata[\"real_time_e\"],\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "\n",
    "    if len(output_vid) == 0:\n",
    "        print(f\"Did not find related answers.\")\n",
    "    for i, elem in enumerate(output_vid.values()):\n",
    "        print(f\"Answer {i + 1}: {elem['vid_source']}\")\n",
    "\n",
    "        answers = list(elem[\"answers\"].values())\n",
    "        answers.sort(key=lambda x: list(map(int, x[\"real_time_s\"].split(\":\"))))\n",
    "        for answer in answers:\n",
    "            print(f\"From {answer['real_time_s']} to {answer['real_time_e']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cd988d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "vid_dir = \"../inputs/test_set\"\n",
    "with open(\"../captions_ann/final_predictions.json\", \"r\") as f:\n",
    "    pred = json.load(f)\n",
    "\n",
    "doc_all = []\n",
    "for k, v in pred.items():\n",
    "    v.sort(key=lambda x: x[\"event_id\"])\n",
    "    doc = build_corpus(os.path.join(vid_dir, f\"{k}.mp4\"), v)\n",
    "    doc_all.extend(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8de0d8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorstore = Chroma.from_documents(\n",
    "#    documents=doc_all, \n",
    "#    embedding=OpenAIEmbeddings(),\n",
    "#    persist_directory=\"../chroma_db\"\n",
    "#)\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=\"../chroma_db\",\n",
    "    embedding_function=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"lambda_mult\": 0.1, \"k\": 10},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98a7b721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1: https://www.youtube.com/watch?v=mL-50vtXHdo&t=47s\n",
      "From 0:2 to 1:4\n",
      "Answer 2: https://www.youtube.com/watch?v=Cec1-mcZOp8\n",
      "From 0:15 to 0:41\n",
      "Answer 3: https://www.youtube.com/watch?v=kSpggqOLgaU\n",
      "From 5:9 to 6:58\n",
      "Answer 4: https://www.youtube.com/watch?v=LqMs2kA5Y88\n",
      "From 2:21 to 2:52\n"
     ]
    }
   ],
   "source": [
    "question = \"Are there any medical machines available?\"\n",
    "pipeline(question, retriever)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
