{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_nms(det, dets, thresh): \n",
    "    \"\"\"Pure Python NMS baseline.\"\"\" \n",
    "\n",
    "    x1 = det[\"timestamp\"][0]\n",
    "    x2 = det[\"timestamp\"][1]\n",
    "    sentence_score = det[\"sentence_score\"]\n",
    "\n",
    "    timestamp = np.array([elem[\"timestamp\"] for elem in dets])\n",
    "    d1 = timestamp[:, 0]\n",
    "    d2 = timestamp[:, 1]\n",
    "\n",
    "    xx1 = np.maximum(x1, d1)\n",
    "    xx2 = np.minimum(x2, d2)\n",
    "    overlap = xx2 - xx1\n",
    "    not_overlapped = overlap < 0\n",
    "\n",
    "    xx1 = np.minimum(x1, d1)\n",
    "    xx2 = np.maximum(x2, d2)\n",
    "    iou = abs(overlap / (xx2 - xx1 + 1e-6))\n",
    "    not_the_same_det = iou < thresh\n",
    "\n",
    "    kept_dets = np.array(list(zip(not_overlapped, not_the_same_det))).any(1)\n",
    "\n",
    "    other_ss = [elem[\"sentence_score\"] for elem, keep in zip(dets, kept_dets) if not keep]\n",
    "    other_s = [elem[\"sentence\"] for elem, keep in zip(dets, kept_dets) if not keep]\n",
    "    better_cap = None\n",
    "    if other_ss:\n",
    "        other_best = max(other_ss)\n",
    "        find_better_one = None if other_best <= sentence_score else other_ss.index(other_best)\n",
    "        if find_better_one is not None:\n",
    "            better_cap = other_s[find_better_one]\n",
    "    return [det for keep, det in zip(kept_dets, dets) if keep], better_cap\n",
    "\n",
    "def get_video_duration(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return None\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = frame_count / fps\n",
    "    cap.release()\n",
    "    return frame_count, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_file = \"../captions_ann/gvl_pred.json\"\n",
    "video_dir = \"../inputs/test_set\"\n",
    "thresh = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pred_file, \"r\") as f:\n",
    "    pred = json.load(f)\n",
    "\n",
    "post_ann = {}\n",
    "for vid_name, predictions in pred[\"results\"].items():\n",
    "    pred_event_count = np.mean([elem[\"pred_event_count\"] for elem in predictions])\n",
    "    predictions.sort(key=lambda x: x[\"proposal_score\"], reverse=True)\n",
    "\n",
    "    output = []\n",
    "    for i in range(int(pred_event_count)):\n",
    "        first = predictions.pop(0)\n",
    "        first[\"event_id\"] = i\n",
    "        first[\"sentence\"] = [first[\"sentence\"]]\n",
    "        output.append(first)\n",
    "\n",
    "        if predictions:\n",
    "            predictions, better_cap = modified_nms(first, predictions, thresh)\n",
    "            if better_cap:\n",
    "                output[-1][\"sentence\"][0] = better_cap\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    post_ann[vid_name] = output\n",
    "\n",
    "with open(\"post_predictions.json\", \"w\") as f:\n",
    "    json.dump(post_ann, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vast_ann = []\n",
    "for vid_name, predictions in post_ann.items():\n",
    "    frame_count, duration = get_video_duration(os.path.join(video_dir, vid_name) + \".mp4\")\n",
    "    for elem in predictions:\n",
    "        ann_i = {\n",
    "            \"video_id\": f\"{os.path.join(video_dir, vid_name)}.mp4@{elem['event_id']}\",\n",
    "            \"caption\": [elem[\"sentence\"]],\n",
    "            \"timestamp\": (np.array(elem[\"timestamp\"]) / duration * frame_count).astype(int).tolist(),\n",
    "            \"event_id\": elem[\"event_id\"]\n",
    "        }\n",
    "        vast_ann.append(ann_i)\n",
    "\n",
    "with open(\"vast_inference.json\", \"w\") as f:\n",
    "    json.dump(vast_ann, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cb_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
